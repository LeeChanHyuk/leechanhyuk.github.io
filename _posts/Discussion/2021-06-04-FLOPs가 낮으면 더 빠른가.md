---
title: "두 모델 중, FLOPs가 상대적으로 낮은 모델의 Inference time이 더 빠른가?"
date: 2021-06-04 16:59:00
author: Leechanhyuk
categories: Discussion
tags:	Discussion
use_math: true
cover: "/assets/instacode.png"
toc: true
---

# FLOPs

 - FLOPs : **FL**oating point **OP**eration**S**

 - 부동 소수점 연산이 몇 번 시행되었는가?

 - 딥러닝에서 모델의 크기를 나타내는데 주로 사용된다.

# FLOPs가 적으면 Inference가 더 빠른가?

 - 이 부분에 대해서는 '모바일 장치에서 캐시 및 메모리 접근이 CNN 성능에 미치는 영향 분석', 한국소프트웨어종합학술대회, 2018 논문을 참조해서 적는다.

 - http://nyx.skku.ac.kr/wp-content/uploads/2018/12/18-719.pdf

 <img src="/assets/image/FLOPS/one.PNG" width="450px" height="300px" title="title" alt="title">

 - 위 사진대로, FLOPs와 Inference time은 비례하지만, 항상 그 비례 상수가 같지는 않다.

 - 그 이유는, 논문에 따르면 FLOPs 이외에도 메모리 접근 비용 / 병렬 처리 수준등의 다른 변수들이 있기 때문에 FLOPs 하나 만으로는 네트워크를 다양한 면에서 최적화했다고 보기는 힘들다.

 - 위 논문에서는 추론 시간, FLOPs, 메모리 접근 횟수, 캐시 접근 횟수 등의 변수에 대해서 모델을 up-scaling하며 실험했다.

 - 결과는 FLOPs는 비례하지만, 비례 상수가 모델마다 다르고 / Parameter 수는 추론 시간과 관계가 없고 / 캐시 접근 횟수는 추론 시간과 비례하지만, 캐시 접근 횟수가 높은 모델이 더 빠른 경우도 있어서 해석하기 힘들고 / 메모리 접근량이 추론 시간과 가장 유사한 증가 추세를 보인다.

 - 결론적으로는 FLOPs와 메모리 접근량을 함께 고려하는게 가장 Inference time을 측정하기 좋은 지표이다.

 - 아래는 추론 시간 - FLOPs, 메모리 접근량 - FLOPs의 결과 그래프를 나타낸다.

 <img src="/assets/image/FLOPS/two.PNG" width="450px" height="300px" title="title" alt="title">
