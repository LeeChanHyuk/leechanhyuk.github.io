---
title: "[ML]  NBDT- NEURAL-BACKED DECISION TREE"
date: 2021-05-13 21:05:00
author: Leechanhyuk
categories: paper_Review
tags: Computer_Vision Machine_Learning
use_math: true
cover: "/assets/instacode.png"
toc: true
---

* * *
**NBDT - NEURAL-BACKED-DECISION TREE Review**
* * *

<img src="/assets/image/NBDT/front.PNG" width="600px" height="450px" title="title" alt="title">

본 리뷰는 논문 요약 보다는 제가 이해한 틀에 맞춰서 재구성하였습니다.

---

## Abstract

 - Finance나 Medicine 분야는 정확하고, 믿을 수 있는 예측이 중요하다.

 - 지금까지의 Deep learning based decision tree들은 Accuracy와 Interpretability가 양립 관계에 놓여있었다.

 - NBDT는 Accuracy와 Interpretability를 둘 다 잡았다.

 - Acc면에서는 CIFAR Dataset에서 다른 모델보다 16%가 높았고(추후 비교 결과를 생각해 보았을 때 Decision tree를 이용한 모델들과의 비교인 듯 하다.), Backbone model의 성능을 2% 끌어올렸다.

 - Interpretability면에서는 model의 약점 및 Dataset debugging을 용이하게 함으로 써 더욱 향상시켰다.

 - Code는  github.com/alvinwan/neural-backed-decision-trees 에서 확인 가능하다.

## Introduction

 - 지금까지의 Deep learning은 Blackbox였다.

 - Blackbox를 explain해보고자 한 방법은 크게 Saliency maps / Sequential decision process로 나뉜다.

 - Saliency map은 과정에서 잘못된 부분이 있었다고 해도, 결과가 바르게 나온다면 그 잘못된 것을 확인할 수 없는 한계점이 있다.

 - 따라서 본 논문은 model의 decision process를 rule-based의 decision tree로 나타냄으로써 model에 대한 insight를 향상시켰다.

 - 현 decision tree 관련 연구들은 다른 ML Model과 비교해 ACC가 낮고 / ACC 향상을 위해 Interpretability를 낮추고 / tree structure이 model의 안정성을 낮추는 한계가 있었다.

 - 현재는 Interpretability에 대한 Universial한 Definition이 없었다.

 - 따라서 이전 연구(Poursabzi-Sangdeh et al)의 정의에 따라 일정 수준 이상 불완전한 모델에서 사람이 제대로 Prediction을 판별할 수 있을 때 Interpretability가 좋다고 판단했다.

 - 따라서 본 논문에서는 model, dataset을 debugging할 수 있고, 사람의 신뢰를 얻을 수 있게 하는 것을 목표로 했다.

 - 이를 위해 NBDT에서는, 마지막 FC를 Differentiable oblique Decision Tree로 변경하고 Hierarchical softmax를 사용하지 않았다.

## Contribution

 - Tree supervision loss를 Propose했다. 이 Loss를 사용해서 WideResnet, EfficientNet을 Outperform했다.

 - Oblique decision tree를 위한 alternative hierarchies를 Propose했다. Pretrained parameters를 활용했고, infomation gain 위주로 학습 된 모델을 Outperform했다.

 - NBDT가 Model의 Interpretability를 향상시킨다는 것을 확인했다.

## Related works

 - Saliency maps

 - Transfer to explainable models

 - Hybrid models

 - Hierarchical Classification

## Method

 - 모델은 Backbone Network - Hierarchical Decision Tree (FC를 대체)의 형태로 이루어진다.

## Model - Decision tree configuration

<img src="/assets/image/NBDT/figure2.PNG" width="600px" height="450px" title="title" alt="title">

 - 우선 Backbone network를 training 시킨다.

 - Backbone network의 FC layer의 마지막 단 Weight를 L2 Norm으로 나누어서 Normalize 시킨다. (A)

 - 그 후 그 Parameters를 agglomerative clustering을 하고 Tree의 Leafnode로 사용한다. (B)

 - 이 단계에서 leftnode는 $R^(D*K)$ 인 것을 보면 FC의 개수가 D일 때 agglomerative clustering을 해서 K개의 class로 만드는 것 같다.

 - Leafnode로 부터 출발해서 자식 노드의 평균으로 부모 노드를 설정한다. (C)

 - 이렇게 쭉 올라가서 Ancestor node까지 죽 올라간다. (D)

## Model - inference

 1. Seed oblique decision rule weights with neural networks weights.

   - 앞서 설명한대로, FC의 마지막 Linear layer에서 K개의 Node를 추출해내고, 이를 Leaf node로 써서 N-K개의 inner node를 만든다.

 2. Compute node probabilities

   - 자식 노드의 확률은 Softmax inner product로 계산한다.? **(조사 필요)**

 3. Pick a left using path probabilities

   - Class K의 Probability는 아래 공식과 같이 나타난다.

<img src="/assets/image/NBDT/one.PNG" width="450px" height="300px" title="title" alt="title">

<img src="/assets/image/NBDT/two.PNG" width="450px" height="300px" title="title" alt="title">

   - $P_k$는 Root node의 Probability를 의미. $C_k(i)$는 i번째 자식 노드를 의미힌다. 즉, Class k의 확률은 Root node로 부터 쭉 곱해져온 것이 된다는 것이다. (1)

   - Class의 결정은 모든 Leaf node, 즉 Class를 의미하는 node들 간의 Argmax로 결정한다. (2)

## Labeling decision nodes with WORDNET

 - Subtree 구조를 완성하기 위해서, 우선 ancestor node부터 먼저 찾았다.

 - 이 "찾았다"는 의미는 아무래도, WordNet은 의미를 가진 구조체이지만, 실제 학습시에는 어떤 노드에 어떤 객체를 할당한다는 것이 불가능할테니까 일단 학습시키고 쭉 올라가서 공통된 노드들의 속성을 추정하는 식으로 구성한 것 같다.

 - 또한 추상적인 개념은 여기서는 반영하지 못했다.

## Fine-Tuning with tree superviion loss

<img src="/assets/image/NBDT/three.PNG" width="450px" height="300px" title="title" alt="title">

 - Normal cross-entropy loss는 각 Leaf Node. 즉, 각 Class에 대해 학습시킬 수는 있지만, 각 Inner-Node에 대해 학습시킬 수는 없다. ($L_original$)

 - 따라서 Tree supervision loss를 제안한다.($L_soft$)

 - 이 Loss는 Path probabilities에 대한 Loss이다.

 - 본 Loss는 Leaf node가 잘 학습되지 않은 Training 초기에는 Training에 좋지 않은 영향을 준다.

 - 따라서 CIFAR 100 Dataset으로 훈련시킬 때에는 $W_T$를 0부터 0.5까지 점진적으로 증가시키며 훈련시켰다.

 - $\beta_t$는 [0 1] 구간에 속한 Parameter로 선형적으로 감소시켰다.

 - Backbone 모델의 ACC보다 더 잘 나오지 않을 경우에는 $L_soft$만 활성화한채로 fine-tuning 시켰다.

 - Hierarchical softmax와는 다르게, path-probability cross entropy loss인 $L_soft$는 Hierarchy 초반에 불균형하게 Up-weighting해서 high-Level decision을 도왔다.

 - 이것은 Backbone network보다 Out-sample을 분류하는데서 16%의 정확도 향상을 만들어냈다.

## Experiments

 - 