---
title: "[Object detection] YOLOX: Exceeding YOLO Series in 2021"
date: 2021-08-25 21:05:00
author: Leechanhyuk
categories: Paper_review
tags: Computer_vision
use_math: true
cover: "/assets/instacode.png"
toc: true
---

* * *

**YOLOX: Exceeding YOLO Series in 2021 review**

<img src="/assets/image/yolox/figure1.png" width="600px" height="450px" title="title" alt="title">

# 0. Abstract

 - YOLO Detector에 anchor-free manner를 적용하고, 다른 detection techniques (decoupled head, leading label assignment strategy SimOTA)을 적용함.

 - YOLO Nano에 적용하여, 0.91M parameters, 1.08G FLOPs, 25.3AP on COCO.

 - YOLOV3에 적용하여, 47.3AP 달성

 - YOLOX-L은 YOLO V4-CSP, VOLOV5-L과 비슷한 Parameter 수를 가지지만, 50.0 AP 달성

 - Won 1st prize on Autonomous driving workshop at CVPR 2021

# 1. Introduction

 - YOLO Series는 해당 시대에 가장 뛰어난 detection technique를 적용해서 좋은 결과를 냈고, 그 중에서 현재까지는 YOLO V5의 성능이 가장 뛰어나다.

 - 그러나 아직 Anchor-free / advanced label assignment strategies, NMS-Free 등은 적용한적이 없다.

 - Anchor-free를 적용하기에는 YOLO-V3가 가장 적합해서 해당 모델을 Baseline으로 활용

 - YOLO V5 + CSPNet backbone + PAN head (알기) = 50.0% AP in COCO. 다른 YOLO 보다 뛰어남.

 - Tiny, nano version에서도 다른 YOLO보다 뛰어남.

# 2. YOLOX

  - ## 2.1. YOLOX-DarkNet53

    - ### Implementation details

     - 기존 YOLO V3 훈련 방식과 같음

     - 300 Epochs 중 5 Epoch 마다 warm up in COCO 2017

     - SGD 사용 (Momentum 0.9, weight decay = 0.0005)
     
     - Learning Rate는 0.01로 설정 / Cosine lr schedule 사용 / lr = lr*BatchSize/64로 설정

     - Batch size 128 / 8-GPU Device에서

     - Input size는 448부터 832까지 32 strides로

    - ### YOLO V3 baseline

     - Backbone = DarkNet53 + SPPNet (알기)

     - EMA weights updating 적용

     - Cosine lr schedule (알기)

     - IoU Loss (For regression), IoU-aware branch. (알기)
     
     - BCE Loss (For classification score and objectness score)

     - Augmentation = ColorJitter + RandomHorizontalFlip

    - ### Decoupled head

     - Object detection에서 regression과 classification 사이의 conflict는 유명한 문제이다.

     - 따라서 해결책으로, Decoupled head를 사용한다.

     - YOLO Series의 backbone과 feature pyramids는 지속적으로 발전해왔고, 여전히 coupled 된 head를 사용했다.

      <img src="/assets/image/yolox/figure2.png" width="600px" height="450px" title="title" alt="title">

      - 실험을 통해 Coupled detection head가 performance를 낮추는 것을 확인했다.

      - 1. Decoupled head 사용하니까 속도가 빨라졌다.

      <img src="/assets/image/yolox/figure3.png" width="600px" height="450px" title="title" alt="title">

      - 2. AP도 좋아졌다.

      <img src="/assets/image/yolox/table1.png" width="600px" height="450px" title="title" alt="title">

      - 따라서 figure 2와 같이 decoupled head를 사용했고, 1x1 conv를 통해서 채널 수를 감소시키고, 두개의 3x3 conv를 통해서 branch를 나누었다.

      - Batch sisze 1로 설정하였을 때 V100에서 1.1ms의 속도 향상을 가져왔다.

      찾아봐야 할 것. IoU Loss / IoU aware branch / SPPNet / Cosine lr / label assignment strategy SimOTA / PAN Head

    - ### Strong data augmentation

     - Mosaic (YOLO V4, V5 적용) and MixUp 적용

     - 마지막 15 Epoch에는 적용하지 않음.

     - Strong data augmentation을 적용하면 ImageNet pre-training이 더 이상 효과적이지 않다는 것을 발견.

     - 따라서 모든 모델을 scratch로 부터 훈련시킴.



